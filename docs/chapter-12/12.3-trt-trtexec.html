
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>12.3 trtexec 工具使用 · PyTorch实用教程（第二版）</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="余霆嵩">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-intopic-toc/style.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-donate/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="12.4-trt-tools.html" />
    
    
    <link rel="prev" href="12.2-trt-workflow.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"repo":"TingsongYu/PyTorch-Tutorial-2nd","types":["star","watch","fork"],"size":"small"};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../preface.html">
            
                <a href="../preface.html">
            
                    
                    前言
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">上篇：PyTorch基础</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../chapter-1/">
            
                <a href="../chapter-1/">
            
                    
                    第一章 PyTorch 简介与安装
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../chapter-1/1.1-PyTorch-Introduction.html">
            
                <a href="../chapter-1/1.1-PyTorch-Introduction.html">
            
                    
                    1.1 PyTorch 初认识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../chapter-1/1.2-Anaconda.html">
            
                <a href="../chapter-1/1.2-Anaconda.html">
            
                    
                    1.2 环境配置之Anaconda
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="../chapter-1/1.3-Pycharm.html">
            
                <a href="../chapter-1/1.3-Pycharm.html">
            
                    
                    1.3 环境配置之-IDE——Pycharm & VS Code
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.4" data-path="../chapter-1/1.4-CUDA&cuDNN.html">
            
                <a href="../chapter-1/1.4-CUDA&cuDNN.html">
            
                    
                    1.4 环境配置之CUDA&cuDNN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.5" data-path="../chapter-1/1.5-PyTorch-install.html">
            
                <a href="../chapter-1/1.5-PyTorch-install.html">
            
                    
                    1.5 环境配置之PyTorch系列包
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.6" data-path="../chapter-1/1.6-JupyterNotebook-install.html">
            
                <a href="../chapter-1/1.6-JupyterNotebook-install.html">
            
                    
                    1.6 环境配置之Jupyter Notebook
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../chapter-2/">
            
                <a href="../chapter-2/">
            
                    
                    第二章 PyTorch 核心模块
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.2.1" data-path="../chapter-2/2.1-module-tree.html">
            
                <a href="../chapter-2/2.1-module-tree.html">
            
                    
                    2.1 PyTorch 模块结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.2" data-path="../chapter-2/2.2-covid-19-cls.html">
            
                <a href="../chapter-2/2.2-covid-19-cls.html">
            
                    
                    2.2 新冠肺炎分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.3" data-path="../chapter-2/2.3-datastruct-tensor.html">
            
                <a href="../chapter-2/2.3-datastruct-tensor.html">
            
                    
                    2.3 核心数据结构——Tensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.4" data-path="../chapter-2/2.4-method-tensor.html">
            
                <a href="../chapter-2/2.4-method-tensor.html">
            
                    
                    2.4 张量的相关函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.5" data-path="../chapter-2/2.5-computational-graphs.html">
            
                <a href="../chapter-2/2.5-computational-graphs.html">
            
                    
                    2.5 自动求导核心——计算图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2.6" data-path="../chapter-2/2.6-autograd.html">
            
                <a href="../chapter-2/2.6-autograd.html">
            
                    
                    2.6 Autograd——自动微分
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../chapter-3/">
            
                <a href="../chapter-3/">
            
                    
                    第三章 PyTorch 数据模块
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.3.1" data-path="../chapter-3/3.1-dataset.html">
            
                <a href="../chapter-3/3.1-dataset.html">
            
                    
                    3.1 Dataset
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.2" data-path="../chapter-3/3.2-dataloader.html">
            
                <a href="../chapter-3/3.2-dataloader.html">
            
                    
                    3.2 DataLoader
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.3" data-path="../chapter-3/3.3-dataset-useful-api.html">
            
                <a href="../chapter-3/3.3-dataset-useful-api.html">
            
                    
                    3.3 Dataset及常用API
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.4" data-path="../chapter-3/3.4-transforms.html">
            
                <a href="../chapter-3/3.4-transforms.html">
            
                    
                    3.4 transforms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3.5" data-path="../chapter-3/3.5-torchvision-dataset.html">
            
                <a href="../chapter-3/3.5-torchvision-dataset.html">
            
                    
                    3.5 torchvision 经典dataset学习
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../chapter-4/">
            
                <a href="../chapter-4/">
            
                    
                    第四章 PyTorch 模型模块
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.4.1" data-path="../chapter-4/4.1-module&Parameter.html">
            
                <a href="../chapter-4/4.1-module&Parameter.html">
            
                    
                    4.1 Module&Parameter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.2" data-path="../chapter-4/4.2-containers.html">
            
                <a href="../chapter-4/4.2-containers.html">
            
                    
                    4.2 Module的容器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.3" data-path="../chapter-4/4.3-common-module.html">
            
                <a href="../chapter-4/4.3-common-module.html">
            
                    
                    4.3 常用网络层
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.4" data-path="../chapter-4/4.4-module-api.html">
            
                <a href="../chapter-4/4.4-module-api.html">
            
                    
                    4.4 Module常用API函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.5" data-path="../chapter-4/4.5-hook-func.html">
            
                <a href="../chapter-4/4.5-hook-func.html">
            
                    
                    4.5 Hook函数及Grad-CAM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.6" data-path="../chapter-4/4.6-classic-model.html">
            
                <a href="../chapter-4/4.6-classic-model.html">
            
                    
                    4.6 经典模型代码分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4.7" data-path="../chapter-4/4.7-weight-init.html">
            
                <a href="../chapter-4/4.7-weight-init.html">
            
                    
                    4.7 权重初始化方法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../chapter-5/">
            
                <a href="../chapter-5/">
            
                    
                    第五章 PyTorch 优化模块
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.5.1" data-path="../chapter-5/5.1-loss-function.html">
            
                <a href="../chapter-5/5.1-loss-function.html">
            
                    
                    5.1 二十一个损失函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5.2" data-path="../chapter-5/5.2-Optimizer.html">
            
                <a href="../chapter-5/5.2-Optimizer.html">
            
                    
                    5.2 十三个优化器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5.3" data-path="../chapter-5/5.3-lr-scheduler.html">
            
                <a href="../chapter-5/5.3-lr-scheduler.html">
            
                    
                    5.3 十四个学习率调整器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../chapter-6/">
            
                <a href="../chapter-6/">
            
                    
                    第六章 PyTorch 可视化模块
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.6.1" data-path="../chapter-6/6.1-tensorboard.html">
            
                <a href="../chapter-6/6.1-tensorboard.html">
            
                    
                    6.1 TensorBoard安装与使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6.2" data-path="../chapter-6/6.2-cnn-visualization.html">
            
                <a href="../chapter-6/6.2-cnn-visualization.html">
            
                    
                    6.2 CNN卷积核与特征图可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6.3" data-path="../chapter-6/6.3-conf_matrix.html">
            
                <a href="../chapter-6/6.3-conf_matrix.html">
            
                    
                    6.3 混淆矩阵与训练曲线可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6.4" data-path="../chapter-6/6.4-cam-vis.html">
            
                <a href="../chapter-6/6.4-cam-vis.html">
            
                    
                    6.4 CAM可视化与hook函数使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6.5" data-path="../chapter-6/6.5-model-print.html">
            
                <a href="../chapter-6/6.5-model-print.html">
            
                    
                    6.5 模型参数打印
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="../chapter-7/">
            
                <a href="../chapter-7/">
            
                    
                    第七章 PyTorch 小技巧汇总
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.7.1" data-path="../chapter-7/7.1-serialization.html">
            
                <a href="../chapter-7/7.1-serialization.html">
            
                    
                    7.1 模型保存与加载
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.2" data-path="../chapter-7/7.2-finetune.html">
            
                <a href="../chapter-7/7.2-finetune.html">
            
                    
                    7.2 Finetune 模型微调
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.3" data-path="../chapter-7/7.3-gpu.html">
            
                <a href="../chapter-7/7.3-gpu.html">
            
                    
                    7.3 GPU使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.4" data-path="../chapter-7/7.4-training-script.html">
            
                <a href="../chapter-7/7.4-training-script.html">
            
                    
                    7.4 模型训练代码模板
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.5" data-path="../chapter-7/7.5-torchmetrics.html">
            
                <a href="../chapter-7/7.5-torchmetrics.html">
            
                    
                    7.5 TorchMetrics 模型评估指标库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.6" data-path="../chapter-7/7.6-albumentations.html">
            
                <a href="../chapter-7/7.6-albumentations.html">
            
                    
                    7.6 Albumentations 数据增强库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7.7" data-path="../chapter-7/7.7-torchensemble.html">
            
                <a href="../chapter-7/7.7-torchensemble.html">
            
                    
                    7.7 TorchEnsemble 模型集成库
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">中篇：PyTorch 案例应用</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../chapter-8/">
            
                <a href="../chapter-8/">
            
                    
                    第八章 图像项目案例
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="../chapter-8/8.1-classification.html">
            
                <a href="../chapter-8/8.1-classification.html">
            
                    
                    8.1 图像分类——胸部X光肺炎分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="../chapter-8/8.2-segmentation.html">
            
                <a href="../chapter-8/8.2-segmentation.html">
            
                    
                    8.2 图像分割——脑MRI胶质瘤分割
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="../chapter-8/8.3-detection.html">
            
                <a href="../chapter-8/8.3-detection.html">
            
                    
                    8.3 目标检测——无人机检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="../chapter-8/8.4-tracking-1.html">
            
                <a href="../chapter-8/8.4-tracking-1.html">
            
                    
                    8.4 目标跟踪（上）——DeepSORT原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.5" data-path="../chapter-8/8.4-tracking-2.html">
            
                <a href="../chapter-8/8.4-tracking-2.html">
            
                    
                    8.4 目标跟踪（下）——虎门大桥车流量统计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.6" data-path="../chapter-8/8.5-cycleGAN.html">
            
                <a href="../chapter-8/8.5-cycleGAN.html">
            
                    
                    8.5 生成对抗网络——CycleGAN
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.7" data-path="../chapter-8/8.6-diffusion-model.html">
            
                <a href="../chapter-8/8.6-diffusion-model.html">
            
                    
                    8.6 扩散模型——DDPM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.8" data-path="../chapter-8/8.7-image-captioning.html">
            
                <a href="../chapter-8/8.7-image-captioning.html">
            
                    
                    8.7 图像描述——Image Captioning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.9" data-path="../chapter-8/8.8-image-retrieval-1.html">
            
                <a href="../chapter-8/8.8-image-retrieval-1.html">
            
                    
                    8.8 图像检索（上）——理论基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.10" data-path="../chapter-8/8.8-image-retrieval-2.html">
            
                <a href="../chapter-8/8.8-image-retrieval-2.html">
            
                    
                    8.8 图像检索（下）——CLIP+Faiss+Flask的图像检索系统
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../chapter-9/">
            
                <a href="../chapter-9/">
            
                    
                    第九章 自然语言处理项目案例
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.2.1" data-path="../chapter-9/9.1-nlp_introduction.html">
            
                <a href="../chapter-9/9.1-nlp_introduction.html">
            
                    
                    9.1 自然语言处理简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.2" data-path="../chapter-9/9.2-rnn-lstm.html">
            
                <a href="../chapter-9/9.2-rnn-lstm.html">
            
                    
                    9.2 文本分类-RNN-LSTM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.3" data-path="../chapter-9/9.3-seq2seq.html">
            
                <a href="../chapter-9/9.3-seq2seq.html">
            
                    
                    9.3 机器翻译-seq2seq
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.4" data-path="../chapter-9/9.4-transformer.html">
            
                <a href="../chapter-9/9.4-transformer.html">
            
                    
                    9.4 机器翻译-Transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.5" data-path="../chapter-9/9.5-bert.html">
            
                <a href="../chapter-9/9.5-bert.html">
            
                    
                    9.5 命名实体识别-BERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2.6" data-path="../chapter-9/9.6-gpt.html">
            
                <a href="../chapter-9/9.6-gpt.html">
            
                    
                    9.6 文章续写-问答对话-GPT
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../chapter-10/">
            
                <a href="../chapter-10/">
            
                    
                    第十章 大语言模型安装与应用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="../chapter-10/10.1-qwen.html">
            
                <a href="../chapter-10/10.1-qwen.html">
            
                    
                    10.1 Qwen部署与分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="../chapter-10/10.2-chatglm.html">
            
                <a href="../chapter-10/10.2-chatglm.html">
            
                    
                    10.2 ChatGLM3 部署与分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.3" data-path="../chapter-10/10.3-baichuan.html">
            
                <a href="../chapter-10/10.3-baichuan.html">
            
                    
                    10.3 Baichuan2 部署与分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.4" data-path="../chapter-10/10.4-yi.html">
            
                <a href="../chapter-10/10.4-yi.html">
            
                    
                    10.4 Yi 部署与分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.5" data-path="../chapter-10/10.5-gpt-academic.html">
            
                <a href="../chapter-10/10.5-gpt-academic.html">
            
                    
                    10.5 GPT Academic 安装与使用
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">下篇：PyTorch 模型部署</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../chapter-11/">
            
                <a href="../chapter-11/">
            
                    
                    第十一章 ONNX 使用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1.1" data-path="../chapter-11/11.1-onnx-introduction.html">
            
                <a href="../chapter-11/11.1-onnx-introduction.html">
            
                    
                    11.1 ONNX 简介与安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.1.2" data-path="../chapter-11/11.2-onnxruntime-intro.html">
            
                <a href="../chapter-11/11.2-onnxruntime-intro.html">
            
                    
                    11.2 ONNX Runtime 简介与使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.1.3" data-path="../chapter-11/11.3-onnxruntime-advanced.html">
            
                <a href="../chapter-11/11.3-onnxruntime-advanced.html">
            
                    
                    11.3 ONNX Runtime 进阶使用
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="./">
            
                <a href="./">
            
                    
                    第十二章 TensorRT 使用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.2.1" data-path="12.1-trt-install.html">
            
                <a href="12.1-trt-install.html">
            
                    
                    12.1 TensorRT 简介与安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.2" data-path="12.2-trt-workflow.html">
            
                <a href="12.2-trt-workflow.html">
            
                    
                    12.2 TensorRT 工作流及cuda-python
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="4.2.3" data-path="12.3-trt-trtexec.html">
            
                <a href="12.3-trt-trtexec.html">
            
                    
                    12.3 trtexec 工具使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.4" data-path="12.4-trt-tools.html">
            
                <a href="12.4-trt-tools.html">
            
                    
                    12.4 TensorRT 实用工具
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.5" data-path="12.5-trt-python-api.html">
            
                <a href="12.5-trt-python-api.html">
            
                    
                    12.5 TensorRT API 使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.6" data-path="12.6-quantization.html">
            
                <a href="12.6-quantization.html">
            
                    
                    12.6 模型量化基础概念
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.7" data-path="12.7-ptq.html">
            
                <a href="12.7-ptq.html">
            
                    
                    12.7 PTQ 量化实践
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.8" data-path="12.8-qat.html">
            
                <a href="12.8-qat.html">
            
                    
                    12.8 QAT 量化实践
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2.9" data-path="12.9-trt-deploy.html">
            
                <a href="12.9-trt-deploy.html">
            
                    
                    12.9 TensorRT Python 工程化
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >12.3 trtexec 工具使用</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="123-trtexec-&#x5DE5;&#x5177;&#x4F7F;&#x7528;">12.3 trtexec &#x5DE5;&#x5177;&#x4F7F;&#x7528;</h1>
<p>&#x672C;&#x5C0F;&#x8282;&#x4ECB;&#x7ECD;trtexec&#x5DE5;&#x5177;&#x7684;&#x4F7F;&#x7528;&#xFF0C;trtexec&#x53EF;&#x4EE5;&#x5B9E;&#x73B0;onnx&#x6A21;&#x578B;&#x5BFC;&#x51FA;trt&#x6A21;&#x578B;&#x3001;&#x8017;&#x65F6;&#x5206;&#x6790;&#x548C;&#x6A21;&#x578B;&#x4F18;&#x5316;&#x5206;&#x6790;&#x7B49;&#x529F;&#x80FD;&#xFF0C;&#x672C;&#x8282;&#x5C06;&#x5BF9;trtexec&#x7684;&#x8FD0;&#x7528;&#x8FDB;&#x884C;&#x4ECB;&#x7ECD;&#x3002;</p>
<h2 id="trtexec">trtexec</h2>
<p><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec" target="_blank">trtexec</a>&#x662F;&#x5B98;&#x65B9;&#x63D0;&#x4F9B;&#x7684;&#x547D;&#x4EE4;&#x884C;&#x5DE5;&#x5177;&#xFF0C;&#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x4E00;&#x4E0B;&#x4E09;&#x4E2A;&#x65B9;&#x9762;</p>
<ul>
<li>&#x751F;&#x6210;&#x6A21;&#x578B;&#x5E8F;&#x5217;&#x5316;&#x6587;&#x4EF6;&#xFF1A;&#x7531;ONNX&#x6587;&#x4EF6;&#x751F;&#x6210; TensorRT &#x5F15;&#x64CE;&#x5E76;&#x5E8F;&#x5217;&#x5316;&#x4E3A; Plan&#x6587;&#x4EF6;/engine&#x6587;&#x4EF6;</li>
<li>&#x67E5;&#x770B;&#x6A21;&#x578B;&#x6587;&#x4EF6;&#x4FE1;&#x606F;&#xFF1A;&#x67E5;&#x770B; ONNX&#x6587;&#x4EF6;&#x6216; Plan &#x6587;&#x4EF6;&#x7684;&#x7F51;&#x7EDC;&#x9010;&#x5C42;&#x4FE1;&#x606F;</li>
<li>&#x6A21;&#x578B;&#x6027;&#x80FD;&#x6D4B;&#x8BD5;&#xFF1A;&#x6D4B;&#x8BD5; TensorRT &#x5F15;&#x64CE;&#x57FA;&#x4E8E;&#x968F;&#x673A;&#x8F93;&#x5165;&#x6216;&#x7ED9;&#x5B9A;&#x8F93;&#x5165;&#x4E0B;&#x7684;&#x6027;&#x80FD;</li>
</ul>
<p>trtexec&#x63D0;&#x4F9B;&#x4E86;&#x5927;&#x91CF;&#x53C2;&#x6570;&#xFF0C;&#x6574;&#x4F53;&#x53EF;&#x5206;&#x4E3A;&#x6784;&#x5EFA;&#x548C;&#x8FD0;&#x884C;&#x4E24;&#x4E2A;&#x9636;&#x6BB5;&#x3002;</p>
<p><strong>&#x6784;&#x5EFA;&#x9636;&#x6BB5;&#x5E38;&#x7528;&#x53C2;&#x6570;</strong></p>
<pre><code class="lang-markdown">--onnx=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">model</span>&gt;</span></span>: onnx&#x6587;&#x4EF6;&#x8DEF;&#x5F84;
--minShapes=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">shapes</span>&gt;</span></span>, 
--optShapes=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">shapes</span>&gt;</span></span>, and 
--maxShapes=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">shapes</span>&gt;</span></span>: &#x5F53;&#x662F;onnx&#x6A21;&#x578B;&#x65F6;&#xFF0C;&#x53EF;&#x6307;&#x5B9A;batchsize&#x7684;&#x52A8;&#x6001;&#x8303;&#x56F4;&#x3002;
&#x2013;-memPoolSize=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">pool_spec</span>&gt;</span></span>: &#x4F18;&#x5316;&#x8FC7;&#x7A0B;&#x53EF;&#x4F7F;&#x7528;&#x7684;&#x6700;&#x5927;&#x5185;&#x5B58;
--saveEngine=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x4FDD;&#x5B58;&#x7684;&#x6587;&#x4EF6;&#x8F93;&#x51FA;&#x8DEF;&#x5F84;
--fp16, --int8, --noTF32, and --best: &#x6307;&#x5B9A;&#x6570;&#x636E;&#x7CBE;&#x5EA6;
--verbose: &#x662F;&#x5426;&#x9700;&#x8981;&#x6253;&#x5370;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#x3002;&#x9ED8;&#x8BA4;&#x662F;&#x4E0D;&#x6253;&#x5370;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#x3002;
--skipInference: &#x521B;&#x5EFA;&#x5E76;&#x4FDD;&#x5B58;&#x5F15;&#x64CE;&#x6587;&#x4EF6;&#xFF0C;&#x4E0D;&#x6267;&#x884C;&#x63A8;&#x7406;&#x8FC7;&#x7A0B;&#x3002;
--timingCacheFile=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x8BB0;&#x5F55;&#x6BCF;&#x4E2A;tensor&#x7684;&#x6700;&#x5C0F;&#x6700;&#x5927;&#x503C;&#x3001;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#x7B49;,&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x5206;&#x6790;&#x91CF;&#x5316;&#x6548;&#x679C;&#x3002;
--dumpLayerInfo, --exportLayerInfo=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x6253;&#x5370;&#x53CA;&#x4FDD;&#x5B58;&#x6BCF;&#x4E00;&#x5C42;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;
&#x66F4;&#x591A;&#x9AD8;&#x7EA7;&#x7528;&#x6CD5;&#xFF0C;&#x53C2;&#x8003;&#x5B98;&#x65B9;&#x6587;&#x6863;&#xFF1A;https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec
</code></pre>
<p><strong>&#x8FD0;&#x884C;&#x9636;&#x6BB5;&#x5E38;&#x7528;&#x53C2;&#x6570;</strong></p>
<pre><code class="lang-markdown">--loadEngine=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x8981;&#x52A0;&#x8F7D;&#x7684;&#x6A21;&#x578B;&#x6587;&#x4EF6;
--shapes=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">shapes</span>&gt;</span></span>:&#x6307;&#x5B9A;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x7684;&#x5F62;&#x72B6;
--loadInputs=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">specs</span>&gt;</span></span>: Load input values from files. Default is to generate random inputs.
--warmUp=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">duration</span> <span class="hljs-attr">in</span> <span class="hljs-attr">ms</span>&gt;</span></span>,  &#x70ED;&#x8EAB;&#x9636;&#x6BB5;&#x6700;&#x77ED;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF0C;&#x5355;&#x4F4D;ms
--duration=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">duration</span> <span class="hljs-attr">in</span> <span class="hljs-attr">seconds</span>&gt;</span></span>, &#x6D4B;&#x8BD5;&#x9636;&#x6BB5;&#x6700;&#x77ED;&#x8FD0;&#x884C;&#x65F6;&#x95F4;&#xFF0C;&#x5355;&#x4F4D;s
--iterations=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">N</span>&gt;</span></span>: &#x6D4B;&#x8BD5;&#x9636;&#x6BB5;&#x6700;&#x5C0F;&#x8FED;&#x4EE3;&#x6B21;&#x6570;
--useCudaGraph: &#x91C7;&#x7528; CUDA graph &#x6355;&#x83B7;&#x548C;&#x6267;&#x884C;&#x63A8;&#x7406;&#x8FC7;&#x7A0B;
--noDataTransfers: &#x5173;&#x95ED;host&#x4E0E;device&#x4E4B;&#x95F4;&#x7684;&#x6570;&#x636E;&#x4F20;&#x8F93;
--dumpProfile, --exportProfile=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x6253;&#x5370;&#x53CA;&#x4FDD;&#x5B58;&#x6BCF;&#x4E00;&#x5C42;&#x6027;&#x80FD;&#x4FE1;&#x606F;
--dumpLayerInfo, --exportLayerInfo=<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">file</span>&gt;</span></span>: &#x6253;&#x5370;&#x53CA;&#x4FDD;&#x5B58;&#x6BCF;&#x4E00;&#x5C42;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;
&#x66F4;&#x591A;&#x9AD8;&#x7EA7;&#x7528;&#x6CD5;&#xFF0C;&#x53C2;&#x8003;&#x5B98;&#x65B9;&#x6587;&#x6863;&#xFF1A;https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec
</code></pre>
<h3 id="&#x6848;&#x4F8B;0&#xFF1A;&#x56FA;&#x5B9A;batchsize"><strong>&#x6848;&#x4F8B;0&#xFF1A;&#x56FA;&#x5B9A;batchsize</strong></h3>
<p>&#x8F93;&#x51FA;&#x56FA;&#x5B9A;batchsize&#x7684;engine&#x6587;&#x4EF6;&#xFF0C;&#x8FD9;&#x91CC;&#x9700;&#x8981;&#x6CE8;&#x610F;&#xFF0C;batchsize&#x7684;&#x72B6;&#x6001;&#x9700;&#x8981;&#x4E0E;ONNX&#x5339;&#x914D;&#xFF0C;&#x56E0;&#x6B64;&#x5728;&#x751F;&#x6210;onnx&#x65F6;&#x9700;&#x8981;&#x8BBE;&#x7F6E;&#x597D;&#x3002;</p>
<pre><code class="lang-bash">trtexec --onnx=resnet50_bs_1.onnx --saveEngine=resnet50_bs_1.engine
</code></pre>
<h3 id="&#x6848;&#x4F8B;1--&#x52A8;&#x6001;batchsize&#x4F7F;&#x7528;"><strong>&#x6848;&#x4F8B;1:  &#x52A8;&#x6001;batchsize&#x4F7F;&#x7528;</strong></h3>
<p>resnet50_bs_dynamic.onnx &#x53EF;&#x901A;&#x8FC7;&#x7B2C;&#x5341;&#x4E00;&#x7AE0;&#x7AE0;&#x751F;&#x6210;&#xFF0C;&#x6216;&#x901A;&#x8FC7;&#x767E;&#x5EA6;<a href="https://pan.baidu.com/s/1ZA5Vn4g8Gs3v5r17Y9fw6g" target="_blank">&#x7F51;&#x76D8;&#x4E0B;&#x8F7D;-&#x63D0;&#x53D6;&#x7801;&#xFF1A;whai</a></p>
<pre><code class="lang-bash">trtexec --onnx=resnet50_bs_dynamic.onnx --saveEngine=resnet50_bs_dynamic_1-32-64.engine --timingCacheFile=dynamic-1-32-64.cache --minShapes=input:1x3x224x224 --maxShapes=input:64x3x224x224 --optShapes=input:16x3x224x224
</code></pre>
<p>&#x901A;&#x8FC7;&#x4E0B;&#x8868;&#x53EF;&#x77E5;&#xFF0C;fp32&#x65F6;&#xFF0C;&#x5927;batchsize&#x5E26;&#x6765;&#x541E;&#x5410;&#x91CF;&#x589E;&#x52A0;&#x4E0D;&#x660E;&#x663E;&#xFF0C;&#x56E0;&#x6B64;&#x53EF;&#x8003;&#x8651;&#x65F6;&#x5EF6;&#x7684;&#x5E73;&#x8861;&#xFF0C;&#x9009;&#x62E9;batchsize=8&#x3002;</p>
<table>
<thead>
<tr>
<th>FP32</th>
<th>1-8-64</th>
<th>1-16-64</th>
<th>1-32-64</th>
<th>1-64-64</th>
</tr>
</thead>
<tbody>
<tr>
<td>&#x541E;&#x5410;&#x91CF;&#xFF08; FPS&#xFF09;</td>
<td>952</td>
<td>1060</td>
<td>1126</td>
<td>1139</td>
</tr>
<tr>
<td>&#x65F6;&#x5EF6;&#xFF08;ms&#xFF09;</td>
<td>8.3</td>
<td>14.9</td>
<td>28.2</td>
<td>112</td>
</tr>
</tbody>
</table>
<h3 id="&#x6848;&#x4F8B;2&#xFF1A;fp32&#x3001;fp16&#x3001;int8-&#x6027;&#x80FD;&#x6BD4;&#x8F83;"><strong>&#x6848;&#x4F8B;2&#xFF1A;fp32&#x3001;fp16&#x3001;int8 &#x6027;&#x80FD;&#x6BD4;&#x8F83;</strong></h3>
<p>&#x8FD0;&#x884C;<a href="https://github.com/TingsongYu/PyTorch-Tutorial-2nd/tree/main/code/chapter-12/trtexec_exp" target="_blank">&#x914D;&#x5957;&#x4EE3;&#x7801;</a>&#x4E2D;&#x7684;run.bat/run.sh&#xFF0C;&#x53EF;&#x4EE5;&#x67E5;&#x770B;log&#xFF0C;&#x89C2;&#x5BDF;&#x541E;&#x5410;&#x91CF;&#x3001;&#x65F6;&#x5EF6;&#x7684;&#x53D8;&#x5316;&#x3002;</p>
<p>&#x5982;&#x4E0B;&#x56FE;&#x6240;&#x793A;&#xFF0C;&#x541E;&#x5410;&#x91CF;&#x65B9;&#x9762;</p>
<ul>
<li>fp16&#x76F8;&#x8F83;&#x4E8E;fp32&#x6709;&#x7EA6;2~3&#x500D;&#x63D0;&#x5347;&#xFF0C;int8&#x76F8;&#x8F83;&#x4E8E;fp16&#x7EA6;2&#x500D;&#x63D0;&#x5347;</li>
<li>&#x76F8;&#x540C;&#x7CBE;&#x5EA6;&#x65F6;&#xFF0C;&#x541E;&#x5410;&#x91CF;&#x968F;batchsize&#x589E;&#x52A0;&#xFF0C;&#x4F46;&#x5728;32&#x540E;&#x589E;&#x901F;&#x4E0D;&#x660E;&#x663E;&#x3002;int8&#x968F;&#x7740;batchsize&#x589E;&#x901F;&#x6F5C;&#x529B;&#x66F4;&#x5927;&#x3002;</li>
</ul>
<p>&#x65F6;&#x5EF6;&#x65B9;&#x9762;</p>
<ul>
<li>&#x65F6;&#x5EF6;&#x968F;&#x7740;batchsize&#x662F;&#x7EBF;&#x6027;&#x589E;&#x957F;</li>
<li>fp32, fp16, int8&#x7684;&#x65F6;&#x5EF6;&#x4F9D;&#x6B21;&#x9012;&#x51CF;&#x4E00;&#x534A;</li>
</ul>
<p><img src="imgs/trtexec-f32-f16-int8.jpg" alt="trtexec-f32-f16-int8"></p>
<h3 id="&#x6848;&#x4F8B;3&#xFF1A;&#x67E5;&#x770B;&#x5C42;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;"><strong>&#x6848;&#x4F8B;3&#xFF1A;&#x67E5;&#x770B;&#x5C42;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;</strong></h3>
<p>&#x901A;&#x8FC7;&#x53C2;&#x6570;--dumpLayerInfo --exportLayerInfo&#xFF0C;&#x53EF;&#x4EE5;&#x8F93;&#x51FA;&#x5404;&#x5C42;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;&#xFF0C;&#x4EE5;&#x53CA;&#x878D;&#x5408;&#x60C5;&#x51B5;&#xFF0C;&#x8FD8;&#x6709;&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x5F20;&#x91CF;&#x7684;&#x540D;&#x5B57;&#xFF08;Bindings&#xFF09;</p>
<pre><code class="lang-bash">trtexec --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --skipInference --dumpLayerInfo --exportLayerInfo=<span class="hljs-string">&quot;exportLayerInfo.log&quot;</span>
</code></pre>
<p>&#x5728;exportLayerInfo.log&#x6587;&#x4EF6;&#x4E2D;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x5982;&#x4E0B;&#x4FE1;&#x606F;&#xFF0C;&#x4E3B;&#x8981;&#x5305;&#x62EC;</p>
<ul>
<li><p>&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x5185;&#x5BB9;&#xFF0C;&#x4EE5;&#x53CA;&#x878D;&#x5408;&#x60C5;&#x51B5;&#x201C;Reformatting CopyNode for Input Tensor 0 to Conv_0 + Relu_1&#x201D;</p>
</li>
<li><ul>
<li>Reformatting CopyNode &#x8868;&#x793A; TensorRT &#x5C06;&#x8F93;&#x5165;tensor 0 &#x590D;&#x5236;(Copy)&#x5230; Conv_0 &#x548C; Relu_1 &#x4E24;&#x4E2A;&#x5C42;&#x8FDB;&#x884C;&#x4E86;&#x878D;&#x5408;(Reformatting)&#x3002;&#x8FD9;&#x91CC;&#x7684; Reformatting &#x6307;&#x7684;&#x662F; TensorRT &#x5728;&#x4F18;&#x5316;&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x65F6;,&#x4F1A;&#x5C06;&#x4E00;&#x4E9B;&#x5C42;&#x8FDB;&#x884C;&#x878D;&#x5408;,&#x4EE5;&#x51CF;&#x5C11;&#x5185;&#x5B58;&#x62F7;&#x8D1D;&#x548C;&#x63D0;&#x9AD8;&#x8BA1;&#x7B97;&#x6548;&#x7387;&#x3002;CopyNode &#x5219;&#x8868;&#x793A;&#x63D2;&#x5165;&#x4E86;&#x4E00;&#x4E2A;&#x62F7;&#x8D1D;&#x5C42;,&#x7528;&#x4E8E;&#x5C06;&#x8F93;&#x5165;&#x6570;&#x636E;&#x590D;&#x5236;&#x5230;&#x878D;&#x5408;&#x540E;&#x65B0;&#x7684;&#x5C42;&#x4E2D;&#x3002;</li>
<li>&#x8FD9;&#x79CD;&#x5C42;&#x7684;&#x878D;&#x5408;&#x53EF;&#x4EE5;&#x51CF;&#x5C11;&#x5185;&#x5B58;&#x8BBF;&#x95EE;,&#x4F18;&#x5316;&#x6570;&#x636E;&#x6D41;,&#x4ECE;&#x800C;&#x63D0;&#x5347;&#x63A8;&#x7406;&#x6027;&#x80FD;&#x3002;</li>
</ul>
</li>
<li><p>Bindings&#xFF1A;&#x5305;&#x62EC;&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x5F20;&#x91CF;&#x7684;&#x540D;&#x79F0;&#xFF0C;&#x8FD9;&#x4E2A;&#x5728;onnx&#x5BFC;&#x51FA;&#x65F6;&#x8BBE;&#x5B9A;&#x7684;&#xFF0C;&#x5728;&#x4E0B;&#x6E38;python&#x63A8;&#x7406;&#x4EE3;&#x7801;&#x4E2D;&#x4E5F;&#x4F1A;&#x7528;&#x5230;&#x3002;</p>
</li>
</ul>
<pre><code class="lang-markdown">{&quot;Layers&quot;: [&quot;Reformatting CopyNode for Input Tensor 0 to Conv<span class="hljs-emphasis">_0 + Relu_</span>1&quot;
,&quot;Conv<span class="hljs-emphasis">_0 + Relu_</span>1&quot;
,&quot;MaxPool_2&quot;
,&quot;Conv<span class="hljs-emphasis">_3 + Relu_</span>4&quot;
,&quot;Conv<span class="hljs-emphasis">_5 + Relu_</span>6&quot;
...
,&quot;Reformatting CopyNode for Input Tensor 0 to Gemm_121&quot;
,&quot;Gemm_121&quot;
,&quot;reshape<span class="hljs-emphasis">_after_</span>Gemm_121&quot;
],
&quot;Bindings&quot;: [&quot;input&quot;
,&quot;output&quot;
]}
</code></pre>
<h3 id="&#x6848;&#x4F8B;4&#xFF1A;verbose&#x4E2D;&#x7684;&#x65E5;&#x5FD7;&#x5185;&#x5BB9;"><strong>&#x6848;&#x4F8B;4&#xFF1A;verbose&#x4E2D;&#x7684;&#x65E5;&#x5FD7;&#x5185;&#x5BB9;</strong></h3>
<p>&#x6253;&#x5F00;verbose&#x5F00;&#x5173;&#x540E;&#xFF0C;trtexec&#x5C06;&#x8F93;&#x51FA;&#x8BE6;&#x7EC6;&#x5185;&#x5BB9;&#xFF0C;&#x5305;&#x62EC;&#x4EE5;&#x4E0B;&#x516D;&#x5927;&#x6A21;&#x5757;&#xFF1A;</p>
<ul>
<li>&#x5BFC;&#x5165;&#x6A21;&#x578B;&#x60C5;&#x51B5;&#xFF1A;&#x6A21;&#x578B;&#x683C;&#x5F0F;&#x3001;&#x540D;&#x79F0;</li>
<li>&#x53C2;&#x6570;&#x914D;&#x7F6E;&#x60C5;&#x51B5;&#xFF1A;&#x8BBE;&#x7F6E;&#x4E86;&#x54EA;&#x4E9B;&#x53C2;&#x6570;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#xFF0C;&#x4F8B;&#x5982; --fp16&#x7B49;</li>
<li>&#x8BBE;&#x5907;&#x60C5;&#x51B5;&#xFF1A;&#x5F53;&#x524D;GPU device&#x5177;&#x4F53;&#x4FE1;&#x606F;</li>
<li>&#x8BA1;&#x7B97;&#x56FE;&#x4F18;&#x5316;&#x7EC6;&#x8282;&#xFF1A;&#x8BE6;&#x7EC6;&#x63CF;&#x8FF0;&#x7F51;&#x7EDC;&#x5C42;&#x878D;&#x5408;&#x60C5;&#x51B5;&#xFF0C;&#x8BA1;&#x7B97;&#x56FE;&#x4F18;&#x5316;&#x7ED3;&#x679C;</li>
<li>&#x7F51;&#x7EDC;&#x5C42;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x9009;&#x62E9;&#xFF08;&#x51E0;&#x5343;&#x884C;&#xFF09;&#xFF1A;&#x6253;&#x5370;&#x6BCF;&#x4E2A;&#x7F51;&#x7EDC;&#x5C42;&#x9009;&#x62E9;&#x7684;kernel&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;<strong>&#x6311;&#x9009;&#x8017;&#x65F6;&#x6700;&#x4F4E;&#x7684;&#x65B9;&#x6CD5;</strong></li>
<li>&#x8017;&#x65F6;&#x7EDF;&#x8BA1;&#xFF1A;&#x7EDF;&#x8BA1;&#x63A8;&#x7406;&#x8017;&#x65F6;&#x65F6;&#x95F4;&#xFF0C;&#x5305;&#x62EC;&#x6570;&#x636E;&#x62F7;&#x8D1D;&#x3001;&#x63A8;&#x7406;&#x7B49;&#x8017;&#x65F6;&#x7684;&#x7EDF;&#x8BA1;&#x503C;</li>
</ul>
<pre><code class="lang-bash">trtexec --onnx=resnet50_bs_dynamic.onnx --saveEngine=demo.engine --verbose &gt; verbose.log
</code></pre>
<p>&#x6267;&#x884C;&#x4EE5;&#x4E0B;&#x547D;&#x4EE4;&#xFF0C;&#x53EF;&#x83B7;&#x5F97;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#xFF0C;&#x4E0B;&#x9762;&#x5BF9;&#x4E3B;&#x8981;&#x5185;&#x5BB9;&#x8FDB;&#x884C;&#x4ECB;&#x7ECD;&#x3002;</p>
<h4 id="model-options-&#xFF1A;&#x5305;&#x542B;&#x5BFC;&#x5165;&#x7684;&#x6A21;&#x578B;&#x5185;&#x5BB9;"><strong>Model Options &#xFF1A;&#x5305;&#x542B;&#x5BFC;&#x5165;&#x7684;&#x6A21;&#x578B;&#x5185;&#x5BB9;</strong></h4>
<pre><code class="lang-markdown">[08/20/2023-11:59:45] [I] === Model Options ===
[08/20/2023-11:59:45] [I] Format: ONNX
[08/20/2023-11:59:45] [I] Model: resnet50<span class="hljs-emphasis">_bs_</span>dynamic.onnx
[08/20/2023-11:59:45] [I] Output:
</code></pre>
<h4 id="build-options&#xFF1A;&#x521B;&#x5EFA;trt&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;&#x8BBE;&#x7F6E;"><strong>Build Options&#xFF1A;&#x521B;&#x5EFA;trt&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;&#x8BBE;&#x7F6E;</strong></h4>
<pre><code class="lang-markdown">[08/20/2023-11:59:45] [I] === Build Options ===
[08/20/2023-11:59:45] [I] Max batch: explicit batch
[08/20/2023-11:59:45] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[08/20/2023-11:59:45] [I] minTiming: 1
[08/20/2023-11:59:45] [I] avgTiming: 8
[08/20/2023-11:59:45] [I] Precision: FP32
...
</code></pre>
<h4 id="&#x63A8;&#x7406;&#x8BBE;&#x7F6E;"><strong>&#x63A8;&#x7406;&#x8BBE;&#x7F6E;</strong></h4>
<pre><code class="lang-markdown">[08/20/2023-11:59:45] [I] === Inference Options===
[08/20/2023-11:59:45] [I] Batch: Explicit
[08/20/2023-11:59:45] [I] Input inference shapes: model
[08/20/2023-11:59:45] [I] Iterations: 10
[08/20/2023-11:59:45] [I] Duration: 3s (+ 200ms warm up)
[08/20/2023-11:59:45] [I] Sleep time: 0ms
[08/20/2023-11:59:45] [I] Idle time: 0ms
[08/20/2023-11:59:45] [I] Inference Streams: 1
</code></pre>
<h4 id="&#x65E5;&#x5FD7;&#x8F93;&#x51FA;&#x8BBE;&#x7F6E;"><strong>&#x65E5;&#x5FD7;&#x8F93;&#x51FA;&#x8BBE;&#x7F6E;</strong></h4>
<pre><code class="lang-markdown">[08/20/2023-11:59:45] [I] === Reporting Options ===
[08/20/2023-11:59:45] [I] Verbose: Enabled
[08/20/2023-11:59:45] [I] Averages: 10 inferences
[08/20/2023-11:59:45] [I] Percentiles: 90,95,99
[08/20/2023-11:59:45] [I] Dump refittable layers:Disabled
[08/20/2023-11:59:45] [I] Dump output: Disabled
[08/20/2023-11:59:45] [I] Profile: Disabled
[08/20/2023-11:59:45] [I] Export timing to JSON file: 
[08/20/2023-11:59:45] [I] Export output to JSON file: 
[08/20/2023-11:59:45] [I] Export profile to JSON file:
</code></pre>
<h4 id="&#x8BBE;&#x5907;&#x4FE1;&#x606F;"><strong>&#x8BBE;&#x5907;&#x4FE1;&#x606F;</strong></h4>
<pre><code class="lang-markdown">[08/20/2023-11:59:46] [I] === Device Information ===
[08/20/2023-11:59:46] [I] Selected Device: NVIDIA GeForce RTX 3060 Laptop GPU
[08/20/2023-11:59:46] [I] Compute Capability: 8.6
[08/20/2023-11:59:46] [I] SMs: 30
[08/20/2023-11:59:46] [I] Device Global Memory: 6143 MiB
[08/20/2023-11:59:46] [I] Shared Memory per SM: 100 KiB
[08/20/2023-11:59:46] [I] Memory Bus Width: 192 bits (ECC disabled)
[08/20/2023-11:59:46] [I] Application Compute Clock Rate: 1.702 GHz
[08/20/2023-11:59:46] [I] Application Memory Clock Rate: 7.001 GHz
</code></pre>
<pre><code class="lang-markdown">[03/28/2024-15:01:18] [I] === Device Information ===
[03/28/2024-15:01:20] [I] Available Devices: 
[03/28/2024-15:01:20] [I]   Device 0: &quot;NVIDIA GeForce RTX 4060 Laptop GPU
[03/28/2024-15:01:20] [I] Selected Device: NVIDIA GeForce RTX 4060 Laptop GPU
[03/28/2024-15:01:20] [I] Selected Device ID: 0
[03/28/2024-15:01:20] [I] Compute Capability: 8.9
[03/28/2024-15:01:20] [I] SMs: 24
[03/28/2024-15:01:20] [I] Device Global Memory: 8187 MiB
[03/28/2024-15:01:20] [I] Shared Memory per SM: 100 KiB
[03/28/2024-15:01:20] [I] Memory Bus Width: 128 bits (ECC disabled)
[03/28/2024-15:01:20] [I] Application Compute Clock Rate: 1.89 GHz
[03/28/2024-15:01:20] [I] Application Memory Clock Rate: 8.001 GHz
</code></pre>
<p>&#x8865;&#x5145;&#x4E00;&#x4E2A;4060&#x7684;&#x663E;&#x5361;&#x4FE1;&#x606F;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;SMs&#x662F;&#x5C11;&#x4E8E;3060&#x7684;&#xFF0C;&#x8FD9;&#x4E2A;&#x4E0E;&#x57FA;&#x672C;&#x5382;&#x5546;&#x7684;&#x5200;&#x6CD5;&#x6709;&#x5173;&#x3002;&#x867D;&#x7136;&#x662F;4060&#x7684;&#x8BBE;&#x5907;&#xFF0C;&#x4F46;&#x662F;&#x8BA1;&#x7B97;&#x6027;&#x80FD;&#x6BD4;&#x4E0D;&#x4E0A;3060&#x8BBE;&#x5907;&#x3002;&#x56E0;&#x4E3A;&#x91CC;&#x8FB9;&#x7684;&#x6838;&#x5FC3;&#x2014;&#x2014;SMs&#x662F;&#x5C11;&#x4E8E;3060&#x7684;30&#x4E2A;SM&#x7684;&#x3002;&#x201C;SMs&#x201D; &#x4EE3;&#x8868; &#x201C;Streaming Multiprocessors&#x201D;&#xFF08;&#x6D41;&#x5904;&#x7406;&#x5668;&#xFF09;&#xFF0C;&#x6D41;&#x5904;&#x7406;&#x5668;&#x662F;&#x6267;&#x884C; CUDA &#x6838;&#x5FC3;&#x7684;&#x57FA;&#x672C;&#x5355;&#x5143;&#xFF0C;SM&#x8D8A;&#x5927;&#x7B97;&#x529B;&#x8D8A;&#x5927;&#x3002;</p>
<p><strong>&#x5BF9;&#x4E8E;RTX 4060 Laptop&#xFF0C;&#x5B98;&#x65B9;&#x663E;&#x793A;&#x6709;3072&#x4E2A;CUDA&#x6838;&#x5FC3;&#xFF0C;&#x5BF9;&#x5E94;24&#x4E2A;SM&#xFF0C;&#x5373;&#x4E00;&#x4E2A;SM&#x6709;128&#x4E2A;CUDA&#x6838;&#x5FC3;&#x3002;</strong></p>
<p><strong>&#x5BF9;&#x4E8E;RTX 3060 Laptop&#xFF0C;&#x5B98;&#x65B9;&#x663E;&#x793A;&#x6709;3840&#x4E2A;CUDA&#x6838;&#x5FC3;&#xFF0C;&#x5BF9;&#x5E94;30&#x4E2A;SM&#xFF0C;&#x4E5F;&#x662F;&#x7B26;&#x5408;&#x4E00;&#x4E2A;SM&#x6709;128&#x4E2A;CUDA&#x6838;&#x5FC3;&#x7684;&#x3002;</strong></p>
<p>4060&#x4E0D;&#x4EC5;&#x6D41;&#x5904;&#x7406;&#x5668;&#x5C11;&#xFF0C;&#x5E26;&#x5BBD;&#x4E5F;&#x4F4E;&#xFF0C;128 bits VS 192 bits&#xFF0C;&#x552F;&#x4E00;&#x7684;&#x4F18;&#x70B9;&#x5C31;&#x662F;8GB VS 6GB&#x4E86;&#x3002;</p>
<h4 id="onnx&#x6A21;&#x578B;&#x52A0;&#x8F7D;&#x53CA;&#x521B;&#x5EFA;"><strong>ONNX&#x6A21;&#x578B;&#x52A0;&#x8F7D;&#x53CA;&#x521B;&#x5EFA;</strong></h4>
<p>&#x89E3;&#x6790;&#x6A21;&#x578B;&#x8017;&#x65F6;0.14&#x79D2;&#xFF0C;&#x603B;&#x5171;126&#x5C42;&#xFF0C;&#x540E;&#x7EED;trt&#x4F1A;&#x9488;&#x5BF9;&#x8BE5;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#x3002;</p>
<pre><code class="lang-markdown">[08/20/2023-11:59:52] [I] [TRT] ----------------------------------------------------------------
[08/20/2023-11:59:52] [I] [TRT] Input filename:   resnet50<span class="hljs-emphasis">_bs_</span>dynamic.onnx
[08/20/2023-11:59:52] [I] [TRT] ONNX IR version:  0.0.7
[08/20/2023-11:59:52] [I] [TRT] Opset version:    13
[08/20/2023-11:59:52] [I] [TRT] Producer name:    pytorch
[08/20/2023-11:59:52] [I] [TRT] Producer version: 1.12.0
[08/20/2023-11:59:52] [I] [TRT] Domain:           
[08/20/2023-11:59:52] [I] [TRT] Model version:    0
[08/20/2023-11:59:52] [I] [TRT] Doc string:       
[08/20/2023-11:59:52] [I] [TRT] ----------------------------------------------------------------



[08/20/2023-11:59:52] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[08/20/2023-11:59:52] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[08/20/2023-11:59:52] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
...
[08/20/2023-11:59:52] [V] [TRT] Adding network input: input with dtype: float32, dimensions: (-1, 3, 224, 224)
[08/20/2023-11:59:52] [V] [TRT] Registering tensor: input for ONNX tensor: input

[08/20/2023-11:59:52] [V] [TRT] Importing initializer: fc.weight
[08/20/2023-11:59:52] [V] [TRT] Importing initializer: fc.bias
[08/20/2023-11:59:52] [V] [TRT] Importing initializer: onnx::Conv_497
[08/20/2023-11:59:52] [V] [TRT] Importing initializer: onnx::Conv_498
[08/20/2023-11:59:52] [V] [TRT] Importing initializer: onnx::Conv_500
...
[08/20/2023-11:59:52] [V] [TRT] Searching for input: onnx::Conv_497
[08/20/2023-11:59:52] [V] [TRT] Searching for input: onnx::Conv_498
[08/20/2023-11:59:52] [V] [TRT] Conv<span class="hljs-emphasis">_0 [Conv] inputs: [input -&gt; (-1, 3, 224, 224)[FLOAT]], [onnx::Conv_</span>497 -&gt; (64, 3, 7, 7)[FLOAT]], [onnx::Conv_498 -&gt; (64)[FLOAT]], 
[08/20/2023-11:59:52] [V] [TRT] Convolution input dimensions: (-1, 3, 224, 224)
[08/20/2023-11:59:52] [V] [TRT] Registering layer: Conv<span class="hljs-emphasis">_0 for ONNX node: Conv_</span>0
...
[08/20/2023-11:59:52] [V] [TRT] Marking output_1 as output: output
[08/20/2023-11:59:52] [I] Finished parsing network model. Parse time: 0.141545
[08/20/2023-11:59:52] [V] [TRT] After dead-layer removal: 126 layers
[08/20/2023-11:59:52] [V] [TRT] Graph construction completed in 0.0015515 seconds.
</code></pre>
<h4 id="&#x8BA1;&#x7B97;&#x56FE;&#x4F18;&#x5316;"><strong>&#x8BA1;&#x7B97;&#x56FE;&#x4F18;&#x5316;</strong></h4>
<p>&#x4F18;&#x5316;&#x8BA1;&#x7B97;&#x56FE;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x5F97;&#x63A8;&#x7406;&#x901F;&#x5EA6;&#x66F4;&#x5FEB;&#xFF0C;&#x5728;&#x672C;&#x6848;&#x4F8B;&#x4E2D;&#xFF0C;&#x5C06;&#x6A21;&#x578B;<strong>&#x4ECE;126&#x5C42;&#x4F18;&#x5316;&#x5230;57&#x5C42;</strong></p>
<p>[08/20/2023-11:59:52] [I] [TRT] Graph optimization time: 0.0150853 seconds.</p>
<p>&#x8BA1;&#x7B97;&#x56FE;&#x4F18;&#x5316;&#x4E2D;&#x91C7;&#x7528;&#x4E86;&#x5927;&#x91CF;&#x7684;<strong>&#x5C42;&#x878D;&#x5408;</strong>&#xFF0C;&#x878D;&#x5408;&#x7684;&#x539F;&#x7406;&#x662F;&#x5C3D;&#x53EF;&#x80FD;&#x5730;&#x5408;&#x5E76;&#x4E0D;&#x540C;&#x5C42;&#x4E4B;&#x95F4;&#x76F8;&#x5173;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x907F;&#x514D;&#x4E0D;&#x5FC5;&#x8981;&#x7684;&#x4E2D;&#x95F4;tensor&#x751F;&#x6210;, &#x51CF;&#x5C11;&#x5185;&#x5B58;&#x8BFB;&#x5199;, &#x964D;&#x4F4E;&#x8BA1;&#x7B97;&#x6D88;&#x8017;&#xFF0C;&#x6700;&#x7EC8;&#x63D0;&#x9AD8;&#x63A8;&#x7406;&#x6548;&#x7387;</p>
<p>&#x5E38;&#x89C1;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x6CD5;&#x5982;&#x4E0B;&#xFF1A;</p>
<ul>
<li><p>ConstShuffleFusion: &#x5728;fc&#x5C42;&#x7684;bias&#x4E2D;&#x4F7F;&#x7528;,&#x53EF;&#x4EE5;&#x5C06;&#x5E38;&#x91CF;shuffle&#x5230;bias&#x6570;&#x636E;&#x4E2D;,&#x51CF;&#x5C11;&#x5197;&#x4F59;&#x8BA1;&#x7B97;&#x3002;</p>
</li>
<li><p>ShuffleShuffleFusion: &#x5728;flatten&#x5C42;&#x4E2D;&#x4F7F;&#x7528;,&#x53EF;&#x4EE5;&#x51CF;&#x5C11;shuffle&#x7684;&#x8BA1;&#x7B97;&#x6B21;&#x6570;&#x3002;</p>
</li>
<li>ConvReshapeBiasAddFusion: &#x5C06;conv&#x5C42;&#x7684;&#x8F93;&#x51FA;reshape,&#x7136;&#x540E;&#x8FDB;&#x884C;bias add&#x7684;&#x8BA1;&#x7B97;&#x878D;&#x5408;&#x5230;&#x4E00;&#x8D77;,&#x51CF;&#x5C11;&#x8FD0;&#x7B97;&#x8017;&#x65F6;&#x3002;</li>
<li>ConvReluFusion: &#x5C06;conv&#x5C42;&#x548C;&#x540E;&#x7EED;&#x7684;Relu&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x5C42;&#x878D;&#x5408;,&#x53EF;&#x4EE5;&#x51CF;&#x5C11;&#x4E00;&#x6B21;Relu&#x7684;&#x8BA1;&#x7B97;&#x3002;</li>
<li>ConvEltwiseSumFusion: &#x5C06;conv&#x5C42;&#x548C;element-wise add&#x5C42;&#x878D;&#x5408;,&#x907F;&#x514D;&#x91CD;&#x590D;&#x8BA1;&#x7B97;&#x3002;</li>
<li>ReduceToPoolingFusion: &#x5C06;reduce&#x5C42;&#x4FEE;&#x6539;&#x4E3A;pooling&#x5C42;,&#x51CF;&#x5C11;&#x8FD0;&#x7B97;&#x6D88;&#x8017;&#x3002;</li>
<li>ConcatReluFusion: &#x5C06;concat&#x5C42;&#x548C;relu&#x5C42;&#x878D;&#x5408;,&#x51CF;&#x5C11;relu&#x8BA1;&#x7B97;&#x6B21;&#x6570;&#x3002;</li>
<li>BiasSoftmaxFusion: &#x878D;&#x5408;bias&#x5C42;&#x548C;softmax&#x5C42;,&#x51CF;&#x5C11;&#x5197;&#x4F59;&#x8BA1;&#x7B97;&#x3002;</li>
</ul>
<pre><code class="lang-markdown">[08/20/2023-11:59:52] [V] [TRT] Running: ConstShuffleFusion on fc.bias
[08/20/2023-11:59:52] [V] [TRT] ConstShuffleFusion: Fusing fc.bias with (Unnamed Layer* 129) [Shuffle]
[08/20/2023-11:59:52] [V] [TRT] After Myelin optimization: 125 layers
...
[08/20/2023-11:59:52] [V] [TRT] After dupe layer removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After final dead-layer removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After tensor merging: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After vertical fusions: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After dupe layer removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After final dead-layer removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After tensor merging: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After slice removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] After concat removal: 57 layers
[08/20/2023-11:59:52] [V] [TRT] Trying to split Reshape and strided tensor
[08/20/2023-11:59:52] [I] [TRT] Graph optimization time: 0.0150853 seconds.
</code></pre>
<h4 id="&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x9009;&#x62E9;"><strong>&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x9009;&#x62E9;</strong></h4>
<p>&#x7F51;&#x7EDC;&#x5C42;&#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;&#x6709;&#x591A;&#x79CD;&#x65B9;&#x5F0F;&#xFF0C;&#x4F8B;&#x5982;<strong>&#x4E0D;&#x540C;&#x7684;&#x5E95;&#x5C42;&#x5E93;&#x3001;&#x4E0D;&#x540C;&#x7684;&#x5B9E;&#x73B0;&#x7B97;&#x6CD5;&#x3001;&#x4E0D;&#x540C;&#x7684;&#x7B97;&#x6CD5;&#x7B56;&#x7565;</strong>&#xFF0C;&#x5728;TensorRT&#x4E2D;&#x4F1A;<strong>&#x628A;&#x6240;&#x6709;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x8DD1;&#x4E00;&#x904D;</strong>&#xFF0C;&#x6311;&#x9009;&#x901F;&#x5EA6;&#x6700;&#x4F18;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x3002;</p>
<p>&#x5728;&#x5B9E;&#x73B0;&#x7F51;&#x7EDC;&#x5C42;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;runner&#x548C;tactic&#x662F;TensorRT&#x4E2D;&#x7528;&#x4E8E;&#x5B9E;&#x73B0;layer&#x7684;&#x5173;&#x952E;&#x7EC4;&#x4EF6;&#x3002;</p>
<ul>
<li>runner&#x4EE3;&#x8868;&#x7740;&#x4E00;&#x79CD;&#x5B9E;&#x73B0;layer&#x7684;&#x7B97;&#x6CD5;&#x6216;&#x4EE3;&#x7801;&#x8DEF;&#x5F84;&#x3002;&#x4F8B;&#x5982;,&#x5377;&#x79EF;&#x5C42;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;cudnn&#x3001;cublas&#x6216;&#x8005;TensorRT&#x81EA;&#x8EAB;&#x7684;cask&#x5B9E;&#x73B0;&#x3002;runner&#x5C01;&#x88C5;&#x4E86;&#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;&#x7B97;&#x6CD5;&#x3002;</li>
<li>tactic&#x4EE3;&#x8868;&#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;&#x65B9;&#x6848;&#x3002;&#x6BCF;&#x4E2A;runner&#x4E0B;&#x9762;&#x53EF;&#x4EE5;&#x6709;&#x591A;&#x4E2A;tactic,&#x5BF9;&#x5E94;&#x4E0D;&#x540C;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x6CD5;&#x3002;&#x4F8B;&#x5982;cask convolution runner&#x4E0B;&#x9762;&#x53EF;&#x4EE5;&#x6709;&#x57FA;&#x4E8E;tensor core&#x7684;tactic,&#x6216;&#x662F;&#x5404;&#x79CD;tile size&#x7684;tactic&#x7B49;&#x7B49;&#x3002;tactic&#x5305;&#x542B;&#x4E86;&#x9488;&#x5BF9;&#x7279;&#x5B9A;layer&#x8FDB;&#x884C;&#x5404;&#x79CD;&#x4F18;&#x5316;&#x7684;&#x4EE3;&#x7801;&#x5B9E;&#x73B0;&#x3002;</li>
</ul>
<p>&#x6240;&#x4EE5;TensorRT&#x901A;&#x8FC7;&#x7EC4;&#x5408;&#x4E0D;&#x540C;&#x7684;runner&#x548C;tactic,&#x5C31;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x5C42;&#x7684;&#x591A;&#x79CD;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#x3002;&#x7136;&#x540E;&#x901A;&#x8FC7;Auto Tuner&#x6765;&#x6D4B;&#x8BD5;&#x4E0D;&#x540C;&#x7EC4;&#x5408;&#x7684;&#x6027;&#x80FD;,&#x9009;&#x62E9;&#x51FA;&#x6700;&#x4F18;&#x7684;&#x5B9E;&#x73B0;&#x3002;</p>
<p>&#x4F8B;&#x5982;,&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x5377;&#x79EF;&#x5C42;:</p>
<ul>
<li>runner&#x53EF;&#x4EE5;&#x662F;cudnn&#x3001;cublas&#x3001;cask convolution&#x7B49;</li>
<li>cask convolution&#x4E0B;&#x9762;&#x53EF;&#x4EE5;&#x6709;&#x57FA;&#x4E8E;tensor core&#x7684;tactic,tile size&#x4E3A;32x32&#x6216;64x64&#x7684;tactic&#x7B49;&#x7B49;</li>
</ul>
<p>&#x6700;&#x7EC8;&#x4F1A;&#x9009;&#x62E9;&#x51FA;cask convolution + 64x64 tile size&#x8FD9;&#x4E2A;tactic&#x7EC4;&#x5408;&#x4F5C;&#x4E3A;&#x6700;&#x4F18;&#x5B9E;&#x73B0;</p>
<p>&#x5728;&#x672C;&#x65E5;&#x5FD7;&#x4E2D;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;runner&#x8DD1;&#x7684;&#x662F;<strong>conv_0 + Relu_1&#xFF0C;&#x6700;&#x7EC8;&#x9009;&#x62E9;&#x7684;Tactic Name&#x662F; 0x9cb304e2edbc1221&#xFF0C;&#x8017;&#x65F6;0.040&#x79D2;&#x3002;</strong></p>
<pre><code class="lang-markdown">
[08/20/2023-11:59:52] [V] [TRT] =============== Computing costs for 
[08/20/2023-11:59:52] [V] [TRT] <span class="hljs-strong">*****</span><span class="hljs-strong">*****</span><span class="hljs-strong">*****</span> Autotuning format combination: Float(150528,50176,224,1) -&gt; Float(802816,12544,112,1) <span class="hljs-strong">*****</span><span class="hljs-strong">*****</span><span class="hljs-strong">*****</span>
[08/20/2023-11:59:52] [V] [TRT] --------------- Timing Runner: Conv<span class="hljs-emphasis">_0 + Relu_</span>1 (CaskConvolution[0x80000009])
[08/20/2023-11:59:52] [V] [TRT] Tactic Name: sm50<span class="hljs-emphasis">_xmma_</span>conv<span class="hljs-emphasis">_fprop_</span>fused<span class="hljs-emphasis">_conv_</span>act<span class="hljs-emphasis">_fp32_</span>NCHW<span class="hljs-emphasis">_fp32_</span>NCHW<span class="hljs-emphasis">_KCRS_</span>fp32<span class="hljs-emphasis">_fp32_</span>fp32<span class="hljs-emphasis">_Accfloat_</span>1<span class="hljs-emphasis">_1_</span>cC1<span class="hljs-emphasis">_dC1_</span>srcVec1<span class="hljs-emphasis">_fltVec1_</span>1<span class="hljs-emphasis">_TP3_</span>TQ4<span class="hljs-emphasis">_C1_</span>R7<span class="hljs-emphasis">_S7_</span>U2_V2 Tactic: 0x0a617a3531b5b6dc Time: 0.102619

[08/20/2023-11:59:52] [V] [TRT] Tactic Name: sm50<span class="hljs-emphasis">_xmma_</span>conv<span class="hljs-emphasis">_fprop_</span>fused<span class="hljs-emphasis">_conv_</span>act<span class="hljs-emphasis">_fp32_</span>NCHW<span class="hljs-emphasis">_fp32_</span>NCHW<span class="hljs-emphasis">_KCRS_</span>fp32<span class="hljs-emphasis">_fp32_</span>fp32<span class="hljs-emphasis">_Accfloat_</span>1<span class="hljs-emphasis">_1_</span>cC1<span class="hljs-emphasis">_dC1_</span>srcVec1<span class="hljs-emphasis">_fltVec2_</span>2<span class="hljs-emphasis">_TP3_</span>TQ4<span class="hljs-emphasis">_C1_</span>R7<span class="hljs-emphasis">_S7_</span>U2_V2 Tactic: 0x520e893be7313ed2 Time: 0.0999131
...
[08/20/2023-11:59:52] [V] [TRT] Conv<span class="hljs-emphasis">_0 + Relu_</span>1 (CaskConvolution[0x80000009]) profiling completed in 0.0647644 seconds. Fastest Tactic: 0x9cb304e2edbc1221 Time: 0.0402286
</code></pre>
<p>&#x6700;&#x7EC8;trt&#x5C06;57&#x4E2A;&#x5C42;&#x90FD;&#x8FDB;&#x884C;&#x4E86;Computing costs&#xFF0C;&#x5F97;&#x5230;&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x7684;&#x6700;&#x4F18;&#x5B9E;&#x73B0;&#x65B9;&#x6848;&#x3002;</p>
<hr>
<p>&#x9664;&#x4E86;&#x7F51;&#x7EDC;&#x5C42;&#xFF0C;&#x8FD8;&#x9700;&#x8981;<strong>reformat layer</strong>&#xFF0C;&#x5B83;&#x7684;&#x4F5C;&#x7528;&#x662F;&#x6539;&#x53D8;tensor&#x7684;&#x683C;&#x5F0F;,&#x5C06;&#x524D;&#x4E00;&#x5C42;&#x7684;&#x8F93;&#x51FA;&#x91CD;&#x65B0;&#x6392;&#x5E03;&#x6210;&#x540E;&#x4E00;&#x5C42;&#x6240;&#x9700;&#x7684;&#x683C;&#x5F0F;&#x3002;&#x8FD9;&#x6837;&#x5C31;&#x53EF;&#x4EE5;&#x4F7F;&#x5F97;&#x4E24;&#x5C42;&#x4E4B;&#x95F4;&#x7684;tensor&#x517C;&#x5BB9;,&#x7136;&#x540E;&#x8FDB;&#x884C;&#x878D;&#x5408;&#x3002;</p>
<p>&#x4F8B;&#x5982;&#xFF1A;Conv_0 + Relu_1&#x5C42;&#x9700;&#x8981;[50176,1:4,224,1]&#x683C;&#x5F0F;&#x7684;tensor&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x800C;&#x8F93;&#x5165;&#x5C42;&#x8F93;&#x51FA;&#x7684;&#x662F;[150528,50176,224,1]&#x683C;&#x5F0F;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x8F93;&#x5165;&#x5C42;&#x548C;Conv_0&#x5C42;&#x4E4B;&#x95F4;&#x52A0;&#x5165;&#x4E86;reformat layer,&#x5C06;tensor&#x91CD;&#x65B0;&#x6392;&#x5E03;&#x6210;Conv&#x5C42;&#x9700;&#x8981;&#x7684;&#x683C;&#x5F0F;&#x3002;</p>
<p>&#x6700;&#x7EC8;&#x6DFB;&#x52A0;&#x4E86;25&#x4E2A;reformat layer&#xFF0C;&#x6A21;&#x578B;&#x53D8;&#x4E3A;&#x4E86;82&#x5C42;&#x3002;</p>
<pre><code class="lang-markdown">...
[08/20/2023-12:00:07] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Gemm<span class="hljs-emphasis">_121 (onnx::Flatten_</span>493) from Float(512,1:4,512,512) to Float(2048,1,1,1)
[08/20/2023-12:00:07] [V] [TRT] Formats and tactics selection completed in 15.1664 seconds.
[08/20/2023-12:00:07] [V] [TRT] After reformat layers: 82 layers
[08/20/2023-12:00:07] [V] [TRT] Total number of blocks in pre-optimized block assignment: 82
[08/20/2023-12:00:07] [I] [TRT] Detected 1 inputs and 1 output network tensors.
</code></pre>
<h4 id="&#x5B58;&#x50A8;&#x7A7A;&#x95F4;&#x5360;&#x7528;&#x60C5;&#x51B5;"><strong>&#x5B58;&#x50A8;&#x7A7A;&#x95F4;&#x5360;&#x7528;&#x60C5;&#x51B5;</strong></h4>
<p>&#x4ECB;&#x7ECD;&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x5B58;&#x50A8;&#x5360;&#x7528;&#x60C5;&#x51B5;&#xFF0C;&#x4EE5;&#x53CA;&#x6C47;&#x603B;&#xFF0C;&#x4F8B;&#x5982;&#x672C;&#x6848;&#x4F8B;&#xFF0C;engine&#x7684;GPU&#x5360;&#x7528;&#x662F;107MB</p>
<pre><code class="lang-markdown">...
[08/20/2023-12:00:07] [V] [TRT] Layer: Conv<span class="hljs-emphasis">_116 + Add_</span>117 + Relu_118 Host Persistent: 7200 Device Persistent: 0 Scratch Memory: 0
[08/20/2023-12:00:07] [V] [TRT] Layer: GlobalAveragePool_119 Host Persistent: 4176 Device Persistent: 0 Scratch Memory: 0
[08/20/2023-12:00:07] [V] [TRT] Layer: Gemm_121 Host Persistent: 6944 Device Persistent: 0 Scratch Memory: 0
[08/20/2023-12:00:07] [V] [TRT] Skipped printing memory information for 26 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[08/20/2023-12:00:07] [I] [TRT] Total Host Persistent Memory: 331696
[08/20/2023-12:00:07] [I] [TRT] Total Device Persistent Memory: 22016
[08/20/2023-12:00:07] [I] [TRT] Total Scratch Memory: 4608
[08/20/2023-12:00:07] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 18 MiB, GPU 107 MiB
</code></pre>
<h4 id="engine&#x6784;&#x5EFA;&#x60C5;&#x51B5;"><strong>engine&#x6784;&#x5EFA;&#x60C5;&#x51B5;</strong></h4>
<p>&#x5BF9;&#x5B8C;&#x6210;&#x597D;&#x7684;engine&#x5404;&#x7F51;&#x7EDC;&#x5C42;&#x3001;&#x7F51;&#x7EDC;&#x5C42;&#x5BF9;&#x5E94;&#x7684;kernel&#x9009;&#x62E9;&#x60C5;&#x51B5;&#x8FDB;&#x884C;&#x6253;&#x5370;&#x3002;</p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x5230;engine&#x7684;&#x6784;&#x5EFA;&#x8017;&#x65F6;15.3&#x79D2;</p>
<pre><code class="lang-markdown">
[08/20/2023-12:00:07] [V] [TRT] Engine generation completed in 15.3167 seconds.
[08/20/2023-12:00:07] [V] [TRT] Deleting timing cache: 214 entries, served 528 hits since creation.
[08/20/2023-12:00:07] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv<span class="hljs-emphasis">_0 + Relu_</span>1, Tactic: 0x00000000000003e8, input (Float[1,3,224,224]) -&gt; Reformatted Input Tensor 0 to Conv<span class="hljs-emphasis">_0 + Relu_</span>1 (Float[1,3:4,224,224])
Layer(CaskConvolution): Conv<span class="hljs-emphasis">_0 + Relu_</span>1, Tactic: 0x9cb304e2edbc1221, Reformatted Input Tensor 0 to Conv<span class="hljs-emphasis">_0 + Relu_</span>1 (Float[1,3:4,224,224]) -&gt; onnx::MaxPool_323 (Float[1,64:4,112,112])
</code></pre>
<h4 id="&#x63A8;&#x7406;&#x8017;&#x65F6;&#x7EDF;&#x8BA1;"><strong>&#x63A8;&#x7406;&#x8017;&#x65F6;&#x7EDF;&#x8BA1;</strong></h4>
<p>&#x8FDB;&#x884C;10&#x6B21;&#x63A8;&#x7406;&#xFF0C;&#x4F9D;&#x6B21;&#x5F97;&#x5230;&#x4EE5;&#x4E0B;&#x4FE1;&#x606F;&#xFF0C;&#x540C;&#x65F6;&#x76F8;&#x5E94;&#x7684;&#x7EDF;&#x8BA1;&#x503C;&#x3002;</p>
<ul>
<li>Throughput&#xFF1A;&#x6A21;&#x578B;&#x7684;&#x63A8;&#x7406;&#x541E;&#x5410;&#x91CF;&#xFF0C;&#x4EE5;&#x6BCF;&#x79D2;&#x63A8;&#x7406;&#x6570;&#x91CF;&#xFF08;QPS&#xFF09;&#x4E3A;&#x5355;&#x4F4D;&#x3002;&#x5B9E;&#x9645;&#x56FE;&#x7247;&#x91CF;&#x9700;&#x8981;&#x4E58;&#x4EE5;batchsize&#x3002;</li>
<li>Latency&#xFF1A;&#x6A21;&#x578B;&#x4E00;&#x6B21;&#x63A8;&#x7406;&#x7684;&#x5EF6;&#x8FDF;&#x65F6;&#x95F4;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;&#xFF0C;&#x5305;&#x62EC;&#x6700;&#x5C0F;&#x503C;&#x3001;&#x6700;&#x5927;&#x503C;&#x3001;&#x5E73;&#x5747;&#x503C;&#x3001;&#x4E2D;&#x4F4D;&#x6570;&#x548C;&#x767E;&#x5206;&#x4F4D;&#x6570;&#xFF08;90%&#x3001;95%&#x548C;99%&#xFF09;&#x3002;</li>
<li>Enqueue Time&#xFF1A;&#x5C06;&#x6570;&#x636E;&#x4F20;&#x8F93;&#x5230;GPU&#x7684;&#x65F6;&#x95F4;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;&#xFF0C;</li>
<li>H2D Latency&#xFF1A;&#x5C06;&#x4E3B;&#x673A;&#x6570;&#x636E;&#x4F20;&#x8F93;&#x5230;GPU&#x7684;&#x5EF6;&#x8FDF;&#x65F6;&#x95F4;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;&#xFF0C;</li>
<li>GPU Compute Time&#xFF1A;&#x6A21;&#x578B;&#x5728;GPU&#x4E0A;&#x8FD0;&#x884C;&#x7684;&#x8BA1;&#x7B97;&#x65F6;&#x95F4;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;</li>
<li>D2H Latency&#xFF1A;&#x4ECE;GPU&#x5C06;&#x6570;&#x636E;&#x4F20;&#x8F93;&#x56DE;&#x4E3B;&#x673A;&#x7684;&#x5EF6;&#x8FDF;&#x65F6;&#x95F4;&#x7EDF;&#x8BA1;&#x4FE1;&#x606F;</li>
<li>Total Host Walltime&#xFF1A;&#x6A21;&#x578B;&#x63A8;&#x7406;&#x7684;&#x603B;&#x65F6;&#x95F4;&#xFF0C;&#x5305;&#x62EC;&#x4F20;&#x8F93;&#x6570;&#x636E;&#x3001;&#x8BA1;&#x7B97;&#x548C;&#x4F20;&#x8F93;&#x6570;&#x636E;&#x56DE;&#x4E3B;&#x673A;&#x7684;&#x65F6;&#x95F4;&#x3002;</li>
<li>Total GPU Compute Time&#xFF1A;&#x6A21;&#x578B;&#x5728;GPU&#x4E0A;&#x7684;&#x603B;&#x8BA1;&#x7B97;&#x65F6;&#x95F4;&#x3002;</li>
</ul>
<pre><code class="lang-markdown">[08/20/2023-12:00:11] [I] === Performance summary ===
[08/20/2023-12:00:11] [I] Throughput: 502.107 qps
[08/20/2023-12:00:11] [I] Latency: min = 1.88583 ms, max = 2.96844 ms, mean = 1.93245 ms, median = 1.91833 ms, percentile(90%) = 1.9592 ms, percentile(95%) = 1.98364 ms, percentile(99%) = 2.34845 ms
[08/20/2023-12:00:11] [I] Enqueue Time: min = 0.312988 ms, max = 1.77197 ms, mean = 0.46439 ms, median = 0.390869 ms, percentile(90%) = 0.748291 ms, percentile(95%) = 0.836853 ms, percentile(99%) = 1.10229 ms
[08/20/2023-12:00:11] [I] H2D Latency: min = 0.0714111 ms, max = 0.225464 ms, mean = 0.0769845 ms, median = 0.0737305 ms, percentile(90%) = 0.088623 ms, percentile(95%) = 0.0947266 ms, percentile(99%) = 0.112671 ms
[08/20/2023-12:00:11] [I] GPU Compute Time: min = 1.80939 ms, max = 2.86005 ms, mean = 1.8518 ms, median = 1.84009 ms, percentile(90%) = 1.87183 ms, percentile(95%) = 1.89734 ms, percentile(99%) = 2.22314 ms
[08/20/2023-12:00:11] [I] D2H Latency: min = 0.00317383 ms, max = 0.0220947 ms, mean = 0.00366304 ms, median = 0.00341797 ms, percentile(90%) = 0.00390625 ms, percentile(95%) = 0.00402832 ms, percentile(99%) = 0.00488281 ms
[08/20/2023-12:00:11] [I] Total Host Walltime: 3.00334 s
[08/20/2023-12:00:11] [I] Total GPU Compute Time: 2.79252 s
[08/20/2023-12:00:11] [I] Explanations of the performance metrics are printed in the verbose logs.
[08/20/2023-12:00:11] [V] 
[08/20/2023-12:00:11] [V] === Explanations of the performance metrics ===
[08/20/2023-12:00:11] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[08/20/2023-12:00:11] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[08/20/2023-12:00:11] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[08/20/2023-12:00:11] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[08/20/2023-12:00:11] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[08/20/2023-12:00:11] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[08/20/2023-12:00:11] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[08/20/2023-12:00:11] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[08/20/2023-12:00:11] [I]
</code></pre>
<h2 id="&#x6848;&#x4F8B;5&#xFF1A;trt&#x6A21;&#x578B;&#x63A8;&#x7406;"><strong>&#x6848;&#x4F8B;5&#xFF1A;trt&#x6A21;&#x578B;&#x63A8;&#x7406;</strong></h2>
<p>&#x901A;&#x8FC7;&#x63A8;&#x7406;trt&#x6A21;&#x578B;&#xFF0C;&#x53EF;&#x4EE5;&#x67E5;&#x770B;&#x7F51;&#x7EDC;&#x5C42;&#x4FE1;&#x606F;&#x3001;&#x7F51;&#x7EDC;&#x5C42;&#x63A8;&#x7406;&#x8017;&#x65F6;&#x60C5;&#x51B5;</p>
<pre><code class="lang-bash">trtexec --loadEngine=resnet50_bs_128_fp32.engine --batch=128 --useCudaGraph --dumpProfile --dumpLayerInfo &gt; inference.log
</code></pre>
<p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x5377;&#x79EF;&#x5C42;&#x8017;&#x65F6;&#x8F83;&#x5927;</p>
<pre><code class="lang-markdown">8/20/2023-17:51:29] [I] === Profile (32 iterations ) ===
[08/20/2023-17:51:29] [I]                                                                    Layer   Time (ms)   Avg. Time (ms)   Median Time (ms)   Time %
[08/20/2023-17:51:29] [I]              Reformatting CopyNode for Input Tensor 0 to Conv<span class="hljs-emphasis">_0 + Relu_</span>1       18.53           0.5790             0.5765      0.6
[08/20/2023-17:51:29] [I]                                                          Conv<span class="hljs-emphasis">_0 + Relu_</span>1      116.65           3.6453             3.6336      3.6
[08/20/2023-17:51:29] [I]                                                                MaxPool_2       51.21           1.6004             1.6005      1.6
</code></pre>
<h2 id="&#x5C0F;&#x8282;"><strong>&#x5C0F;&#x8282;</strong></h2>
<p>&#x672C;&#x8282;&#x4ECB;&#x7ECD;&#x4E86;trtexec&#x57FA;&#x7840;&#x7528;&#x6CD5;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;trtexec&#x5B9E;&#x73B0;onnx&#x6A21;&#x578B;&#x8F6C;trt&#x6A21;&#x578B;&#xFF0C;&#x5E76;&#x4E14;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x52A8;&#x6001;batchsize&#x8BBE;&#x7F6E;&#x3001;&#x534A;&#x7CBE;&#x5EA6;&#x91CF;&#x5316;&#x7684;&#x9009;&#x62E9;&#x3002;</p>
<p>&#x66F4;&#x5168;&#x9762;&#x7528;&#x6CD5;&#x63A8;&#x8350;&#x67E5;&#x770B;&#x5E2E;&#x52A9;&#x6587;&#x6863;&#x4EE5;&#x53CA;<a href="https://github.com/NVIDIA/trt-samples-for-hackathon-cn/blob/master/cookbook/07-Tool/trtexec/command.sh" target="_blank">&#x5B98;&#x65B9;&#x6587;&#x6863;</a>&#x3002;</p>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; TingsongYu 2021 all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A;
2024&#x5E74;04&#x6708;26&#x65E5;21:48:10
</span></footer> <link rel="stylesheet" type="text/css" href="https://storage.googleapis.com/app.klipse.tech/css/codemirror.css"> <script>     window.klipse_settings = {         selector: ".language-klipse, .lang-eval-clojure",         selector_eval_js: ".lang-eval-js",         selector_eval_python_client: ".lang-eval-python",         selector_eval_php: ".lang-eval-php",         selector_eval_scheme: ".lang-eval-scheme",         selector_eval_ruby: ".lang-eval-ruby",         selector_reagent: ".lang-reagent",        selector_google_charts: ".lang-google-chart",        selector_es2017: ".lang-eval-es2017",        selector_jsx: ".lang-eval-jsx",        selector_transpile_jsx: ".lang-transpile-jsx",        selector_render_jsx: ".lang-render-jsx",        selector_react: ".lang-react",        selector_eval_markdown: ".lang-render-markdown",        selector_eval_lambdaway: ".lang-render-lambdaway",        selector_eval_cpp: ".lang-eval-cpp",        selector_eval_html: ".lang-render-html",        selector_sql: ".lang-eval-sql",        selector_brainfuck: "lang-eval-brainfuck",        selector_js: ".lang-transpile-cljs"    }; </script> <script src="https://storage.googleapis.com/app.klipse.tech/plugin/js/klipse_plugin.js"></script>
<script>console.log("plugin-popup....");document.onclick = function(e){ e.target.tagName === "IMG" && window.open(e.target.src,e.target.src)}</script><style>img{cursor:pointer}</style>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="12.2-trt-workflow.html" class="navigation navigation-prev " aria-label="Previous page: 12.2 TensorRT 工作流及cuda-python">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="12.4-trt-tools.html" class="navigation navigation-next " aria-label="Next page: 12.4 TensorRT 实用工具">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"12.3 trtexec 工具使用","level":"4.2.3","depth":2,"next":{"title":"12.4 TensorRT 实用工具","level":"4.2.4","depth":2,"path":"chapter-12/12.4-trt-tools.md","ref":"chapter-12/12.4-trt-tools.md","articles":[]},"previous":{"title":"12.2 TensorRT 工作流及cuda-python","level":"4.2.2","depth":2,"path":"chapter-12/12.2-trt-workflow.md","ref":"chapter-12/12.2-trt-workflow.md","articles":[]},"dir":"ltr"},"config":{"plugins":["copy-code-button","back-to-top-button","expandable-chapters-small","chapter-fold","-lunr","-search","search-pro","github-buttons@2.1.0","github","splitter","sharing-plus","tbfed-pagefooter","intopic-toc","page-toc-button","klipse","pageview-count","donate","popup","3-ba","disqus","emphasize"],"root":".","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy TingsongYu 2021","modify_label":"文件修订时间：","modify_format":"2024年04月26日21:48:10"},"chapter-fold":{},"disqus":{"useIdentifier":false,"shortName":"gitbookuse"},"emphasize":{},"github":{"url":"https://github.com/TingsongYu/PyTorch-Tutorial-2nd"},"intopic-toc":{"isCollapsed":true,"isScrollspyActive":true,"label":"In this article","maxDepth":6,"mode":"nested","selector":".markdown-section h1, .markdown-section h2, .markdown-section h3, .markdown-section h4, .markdown-section h5, .markdown-section h6","visible":true},"splitter":{},"search-pro":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"popup":{},"donate":{"alipay":"https://img.picgo.net/2024/05/18/alipayd96d6d0a325ef7e0.jpg","alipayText":" 支付宝 ↑ ","button":"赏","title":"原创不易，赏！","wechat":"https://img.picgo.net/2024/05/18/wechat2859fc4f155e9302.jpg","wechatText":" 微信 ↑ "},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"page-toc-button":{"maxTocDepth":2,"minTocSize":2},"back-to-top-button":{},"pageview-count":{},"github-buttons":{"repo":"TingsongYu/PyTorch-Tutorial-2nd","types":["star","watch","fork"],"size":"small"},"3-ba":{"configuration":"auto","token":"d00d5236ccf6a1cabd370aa6366ff513"},"expandable-chapters-small":{},"copy-code-button":{},"klipse":{"myConfigKey":"it's the default value"},"sharing":{"qq":true,"all":["douban","facebook","google","hatenaBookmark","instapaper","linkedin","twitter","messenger","qq","qzone","viber","vk","weibo","pocket","stumbleupon","whatsapp"],"douban":false,"facebook":false,"weibo":true,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":false,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"余霆嵩","pdf":{"pageNumbers":true,"fontSize":20,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":36,"bottom":36}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"PyTorch实用教程（第二版）","language":"zh-hans","output.name":"site","gitbook":"3.2.3","description":"PyTorch高质量学习资料"},"file":{"path":"chapter-12/12.3-trt-trtexec.md","mtime":"2024-03-28T07:33:03.800Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-05-18T08:35:59.278Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-intopic-toc/anchor.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-intopic-toc/gumshoe.polyfills.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-intopic-toc/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-donate/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-3-ba/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

